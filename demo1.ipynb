{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253b5816-ca0c-458f-86f4-4a9afe5a5f98",
   "metadata": {},
   "source": [
    "# package install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e40fa41-194e-4302-8880-30546de698f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T09:37:35.734739Z",
     "iopub.status.busy": "2024-07-20T09:37:35.734503Z",
     "iopub.status.idle": "2024-07-20T09:37:47.544874Z",
     "shell.execute_reply": "2024-07-20T09:37:47.544215Z",
     "shell.execute_reply.started": "2024-07-20T09:37:35.734722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting ipex-llm==2.1.0b20240711\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/75/3a/d72e1394c800e1d6dab66319df02e35830e2ee53c1ffee59710180e6a88e/ipex_llm-2.1.0b20240711-py3-none-manylinux2010_x86_64.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/30/c0/b040e127bf824a2e706d1ed0c54adb941659a71d363c3d44ea66beccace6/gradio-4.38.1-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m144.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting streamlit\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c6/51/f140402202af6ce1bf747243f66415c5eb2f43ba2e2ac419a7e855d20673/streamlit-1.36.0-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting altair<6.0,>=5.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/46/30/2118537233fa72c1d91a81f5908a7e843a6601ccc68b76838ebc4951505f/altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.110.2)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/1d/70/07914754979f5dd80bda947a0ffd181c08bfcb137b01c3c0cef45254d271/ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==1.1.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/46/9e/539fa04e70f6aafb5c63dbd856bd218e761a2c30d91f871061d5929c6a2a/gradio_client-1.1.0-py3-none-any.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.2)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/75/06/4df55e1b7b112d183f65db9503bff189e97179b256e1ea450a3c365241e0/importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.5.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/36/06/f5e0d6a921af2feae3c189514ebe12a6b8ab59ffe92c855996bcb4e6aa7f/orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.5.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/3d/47/444768600d9e0ebc82f8e347775d24aef8f6348cf00e9fa0e81910814e6d/python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/5f/d8/537923e6cb27c835b7991f0f0caeb85191aed744a0d808bc71ad598f9df2/ruff-0.5.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/68/4f/12207897848a653d03ebbf6775a29d949408ded5f99b2d87198bc5c93508/tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/20/b5/11cf2e34fbb11b937e006286ab5b8cfd334fde1c8fa4dd7f491226931180/typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
      "Collecting urllib3~=2.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ca/1c/89ffc63a9605b583d5df2be791a27bc1a42b7c32bab68d3c8f2f73a98cd4/urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.1.0->gradio) (2023.12.2)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/58/0a/7570e15661a0a546c3a1152d95fe8c05480459bab36247f0acbf41f01a41/websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ab/4c/b888e6cf58bd9db9c93f40d1c6be8283ff49d88919231afe93a6bcf61626/pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m170.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4)\n",
      "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/24/01/a4034a94a5f1828eb050230e7cf13af3ac23cf763512b6afe008d3def97c/watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonschema>=3.0 (from altair<6.0,>=5.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/69/4a/4f9dbeb84e8850557c02365a0eee0649abe5eb1d84af92a25731c6c0f922/jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting toolz (from altair<6.0,>=5.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b7/8a/d82202c9f89eab30f9fc05380daae87d617e2ad11571ab23d7c13a29bb54/toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.37.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (23.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=5.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ee/07/44bd408781594c4d0a027666ef27fab1e441b109dc3b76b4f836f8fd04fe/jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=5.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b7/59/2056f61236782a2c86b33906c025d4f4a0b17be0161b63b70fd9e8775d36/referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=5.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b8/2a/319eecf21aa0e872a0ee8233507a2a42e02f4b732308834292458fe1302c/rpds_py-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.8/355.8 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5598 sha256=fc82198bc1214dce7fd1ad90b5ea1bdc827928bb05e2d43c91c27acb1a2f4a99\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/e1/de/532f688aa0196c26094c94797bc64fb582880902027092e0d2\n",
      "Successfully built ffmpy\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pydub, ipex-llm, ffmpy, websockets, watchdog, urllib3, toolz, tomlkit, smmap, shellingham, semantic-version, ruff, rpds-py, python-multipart, orjson, importlib-resources, httpcore, blinker, aiofiles, referencing, pydeck, httpx, gitdb, typer, jsonschema-specifications, gitpython, jsonschema, gradio-client, altair, streamlit, gradio\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.3.0 blinker-1.8.2 ffmpy-0.3.2 gitdb-4.0.11 gitpython-3.1.43 gradio-4.38.1 gradio-client-1.1.0 httpcore-1.0.5 httpx-0.27.0 importlib-resources-6.4.0 ipex-llm-2.1.0b20240711 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 orjson-3.10.6 pydeck-0.9.1 pydub-0.25.1 python-multipart-0.0.9 referencing-0.35.1 rpds-py-0.19.0 ruff-0.5.3 semantic-version-2.10.0 shellingham-1.5.4 smmap-5.0.1 streamlit-1.36.0 tomlkit-0.12.0 toolz-0.12.1 typer-0.12.3 urllib3-2.2.2 watchdog-4.0.1 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipex-llm==2.1.0b20240711 gradio streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d275f04d-bca8-46ae-bd0c-e07142295646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T09:37:47.546827Z",
     "iopub.status.busy": "2024-07-20T09:37:47.546529Z",
     "iopub.status.idle": "2024-07-20T09:38:12.829884Z",
     "shell.execute_reply": "2024-07-20T09:38:12.829331Z",
     "shell.execute_reply.started": "2024-07-20T09:37:47.546802Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting PyMuPDF\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e6/24/309ddf66400fcc19bf9ef1089e0857ec4709c0110eb7612c4b81387963c7/PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-vector-stores-chroma\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bb/30/fde34609cb2451f21a7e2c3a381778ab163f93395b85f8fe3ef52baea021/llama_index_vector_stores_chroma-0.1.10-py3-none-any.whl (5.0 kB)\n",
      "Collecting llama-index-readers-file\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/48/85/1ff9a813b326d697564b915f69f4a31339c72777b7a73e18a5cfc025831c/llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6e/f8/eea6c24053cfe9a358698fe415a1379999fe4b7d5af1381bde45c385704f/llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting llama-index\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c7/db/5c9a8ef39225f1870681c89b4f064b561c620054a2898371287000d239ac/llama_index-0.10.56-py3-none-any.whl (6.8 kB)\n",
      "Collecting PyMuPDFb==1.24.6 (from PyMuPDF)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d6/25/1f5a29f9c257027b574e4bf5eed102e7ec9d19b92f058e42164bf042301a/PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting chromadb<0.6.0,>=0.4.0 (from llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/55/97/f863c09b2d0cb320869f96e936408bfad1a47b349821256e9a8a229aebe6/chromadb-0.5.4-py3-none-any.whl (581 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d5/4e/05cd93960956d850c732b55fa592f4928faf3049ca6aaa4899426c466ae3/llama_index_core-0.10.56-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d6/da/6d6416cdce97aba2d700f6751daa3ca0b9278a364f178e9d80b957de3e10/pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a3/cf/0fea4f4ba3fc2772ac2419278aa9f6964124d4302117d61bc055758e000c/striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.22.2)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c2/9a/9a327ff664e4904b6806f716bf705041d3015b99b12568872833df10b18f/llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/8c/1b/554b8da1c7b62a7660a3ab0adfdc13a6046cad45a2490c3640728164f058/llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/0b/ee/68b58b7485c82aadd301ae33f1c6071c04ecfccc9c0bdd599a7dd1ee96b4/llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/7f/a9/5f397906c3bffeb15f94eafa26590f208f957b0670503cdaea7123ef313d/llama_index_indices_managed_llama_cloud-0.2.5-py3-none-any.whl (9.3 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/02/0a/0da9d27b0c3b074c1be1151ff4a4558f077c93df463310adfb47d193dde2/llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/35/e9/efcc69df68a1d4f4ccd9be57fa1aa6a4a27ed3696db7f0362bdabde4d579/llama_index_llms_openai-0.1.26-py3-none-any.whl (11 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/26/18/4c54ba7d2fd833ca93a27503c9069c157c44db6e81739ba583073f2c284d/llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/69/12/d47f38e2f2c18398650db776ab7bec1a7e0ba83664ef04843f664da94126/llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2d/22/39f3ac5702b0e8ffd4d5a383c7cb2da0eb60f63b95f739345e79b66bf977/llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c7/97/d3a73b62cdef72b1d32527d90f4d32432beb2f48861c8177c5f08d46b974/llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (6.0.1)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bf/90/0ce8c76cd2ef8a5e0838d61d6648a1193859e1990bc1d65c8b0fd1f77ca8/SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.9.5)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.12.2)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.26.3)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ef/f2/ad4ded2fa2c932bc7239fc6bf556423462d3068c4b18396ff943787ef424/openai-1.36.0-py3-none-any.whl (328 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.7/328.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.6.0)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (4.9.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.14.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e2/03/f3c8ba0a6b6e30d7d18c40faab90807c9bb5e9a1e3b2fe2008af624a9c97/build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.5.3)\n",
      "Collecting chroma-hnswlib==0.7.5 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/15/a6/0d48ce0d49d947bf7cc75d102555c1be1acfce3b224d222fb0609552ec40/chroma_hnswlib-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.110.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.29.0)\n",
      "Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6c/5f/24cb22118db0e11703b6b80ef9f982eadde21eb585c3a769719e48dce893/posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.17.3)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/7e/b2/4bc5e52c9a23df0ac17dbb23923e609a8269cd67000a712b4f5bcfae1490/opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b0/f3/e24294e7b3f6d2b9aafc97b9b82e214dfe9ffa152dfecbd897e7ffbf6844/opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b8/96/905d575947342c4fd6781a28f6d7bc7f4f6670d45e3b1a85f8a06955c9ae/opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ae/b2/729a959a8aa032bce246c791f977161099ab60fb0188408ccec1bf283b00/opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.15.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c7/2c/94ed7b91db81d61d7096ac8f2d325ec562fc75e35f3baea8749c85b28784/PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.60.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/97/00/21e34b365b895e6faf9cc5d4e7b97dd419e08f8a7df119792ec206b4a3fa/bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.12.3)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/62/a1/2027ddede72d33be2effc087580aeba07e733a7360780ae87226f1f91bd8/kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/03/87/4b01a43336bd506478850d1bc3d180648b2d26b4acf1fc4bf1df72bf562f/mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.10.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.1)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/65/e6/2fdf8f14bbe3e7a3ad4df74eabaeb7a504e677e15c94fb9d579639075c39/minijinja-2.0.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (853 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.2/853.2 kB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-cloud>=0.0.9 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/99/f3/8544705557737555616492898f99f9727c1fc8c47e00fe9a219be4299dd3/llama_cloud-0.0.9-py3-none-any.whl (146 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/98/21/1702c91141c0c06692fde4305b873f06ff1649f622666d6be8fbc7da03aa/llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.38.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.2+cpu)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.11.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (4.0.3)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ae/f3/431b9d5fe7d14af7a32340792ef43b8a714e7726f1d7b69cc4e8e7a3f1d7/pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.0.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.37.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.26.1)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.2.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.12.25)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (14.0)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.12)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/02/48/87422ff1bddcae677fb6f58c97f5cfc613304a5e8ce2c3662760199c0a84/googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/05/02/74ac6619eec78c82a923324f916d3eccd2f2254cf4270b669e96b76bf717/opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/64/ae/d6b5f11ecbffafe8b6d54130fed0cc78aad3711e00074d63a7359d6dcf3b/opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/47/8d/8955c7fbd949e3ea1c186c7422047f675bf4f7c8976afd2fdf713183318e/opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/10/e5/d6fff0a6f6fbddf03c7fb48ab47925581c4f1a8268f9ad98e5ea4a8b90a5/opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/fd/41/28dae1ec1fe0151373f06bd06d9170ca14b52d5b3a6c2dc55f85bc219619/opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a2/7f/26d3d8880ea79adde8bb7bc306b25ca5134d6f6c3006ba464716405b4729/opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (68.0.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/39/e3/893e8757be2612e6c266d9bb58ad2e3651524b5b40cf56761e985a28b13e/asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.0.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (13.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/65/e7/dd5ba95c84047118a363f0755ad78e639e0529be92424bb020496578aa3b/httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ab/ed/12729fba5e3b7e02ee70b3ea230b88e60a50375cf63300db22607694d2f0/uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/3d/ae/e7eddbdca559f14a9a38cf04782a5d715cf350aad498d0862fb02b4ebe10/watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (11.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/96/d7/f318261e6ccbba86bdf626e07cd850981508fdaec52cfcdc4ac1030327ab/marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.17.2)\n",
      "Requirement already satisfied: humanfriendly>=7.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.5.1)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53738 sha256=34b975f5199bc672b137f57d6d2d7150ca4b21b63020a2fc75c1057c557b7c87\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/80/65/2ada18bce5e868ca449f25f16628bb09bb20f9b81d3b63b13a\n",
      "Successfully built pypika\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: striprtf, pypika, monotonic, mmh3, dirtyjson, websocket-client, uvloop, typing-inspect, tqdm, SQLAlchemy, soupsieve, python-dotenv, pyproject_hooks, pypdf, PyMuPDFb, overrides, opentelemetry-util-http, opentelemetry-proto, minijinja, marshmallow, httptools, googleapis-common-protos, distro, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, PyMuPDF, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, dataclasses-json, build, beautifulsoup4, opentelemetry-semantic-conventions, opentelemetry-instrumentation, openai, llama-cloud, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, llama-index-legacy, llama-index-core, sentence-transformers, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-embeddings-huggingface, llama-index-cli, llama-index-agent-openai, chromadb, llama-index-vector-stores-chroma, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 23.9.0 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.6 which is incompatible.\n",
      "easyrobust 0.2.4 requires timm==0.5.4, but you have timm 0.9.16 which is incompatible.\n",
      "fairseq 0.12.2 requires hydra-core<1.1,>=1.0.7, but you have hydra-core 1.3.2 which is incompatible.\n",
      "fairseq 0.12.2 requires omegaconf<2.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 0.9.16 which is incompatible.\n",
      "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyMuPDF-1.24.7 PyMuPDFb-1.24.6 SQLAlchemy-2.0.31 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 beautifulsoup4-4.12.3 build-1.2.1 chroma-hnswlib-0.7.5 chromadb-0.5.4 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 googleapis-common-protos-1.63.2 httptools-0.6.1 kubernetes-30.1.0 llama-cloud-0.0.9 llama-index-0.10.56 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.12 llama-index-core-0.10.56 llama-index-embeddings-huggingface-0.2.2 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.26 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-index-vector-stores-chroma-0.1.10 llama-parse-0.4.9 marshmallow-3.21.3 minijinja-2.0.1 mmh3-4.1.0 monotonic-1.6 openai-1.36.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 pypdf-4.3.0 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 sentence-transformers-3.0.1 soupsieve-2.5 striprtf-0.0.26 tqdm-4.66.4 typing-inspect-0.9.0 uvloop-0.19.0 watchfiles-0.22.0 websocket-client-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF llama-index-vector-stores-chroma llama-index-readers-file llama-index-embeddings-huggingface llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9ed3a-f2a4-436a-b4ca-3a425185826d",
   "metadata": {},
   "source": [
    "# llm download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b4abfa-60df-44e4-b05d-f80df418c51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T09:38:12.830922Z",
     "iopub.status.busy": "2024-07-20T09:38:12.830672Z",
     "iopub.status.idle": "2024-07-20T09:38:33.056728Z",
     "shell.execute_reply": "2024-07-20T09:38:33.056236Z",
     "shell.execute_reply.started": "2024-07-20T09:38:12.830906Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 17:38:14,324 - modelscope - INFO - PyTorch version 2.1.2+cpu Found.\n",
      "2024-07-20 17:38:14,326 - modelscope - INFO - TensorFlow version 2.14.0 Found.\n",
      "2024-07-20 17:38:14,327 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2024-07-20 17:38:14,327 - modelscope - INFO - No valid ast index found from /mnt/workspace/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2024-07-20 17:38:14,375 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 aacbf9e8ebe525a5896d4c89570c0097 and a total number of 976 components indexed\n",
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-20 17:38:15.522713: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-20 17:38:15.525449: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-20 17:38:15.559900: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-20 17:38:15.559919: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-20 17:38:15.559944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-20 17:38:15.566923: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-20 17:38:15.567734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-20 17:38:16.272351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading: 100%|██████████| 660/660 [00:00<00:00, 4.85MB/s]\n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 382kB/s]\n",
      "Downloading: 100%|██████████| 206/206 [00:00<00:00, 1.33MB/s]\n",
      "Downloading: 100%|██████████| 11.1k/11.1k [00:00<00:00, 33.8MB/s]\n",
      "Downloading: 100%|██████████| 1.59M/1.59M [00:00<00:00, 49.7MB/s]\n",
      "Downloading: 100%|█████████▉| 2.88G/2.88G [00:07<00:00, 399MB/s]\n",
      "Downloading: 100%|██████████| 3.47k/3.47k [00:00<00:00, 25.7MB/s]\n",
      "Downloading: 100%|██████████| 6.70M/6.70M [00:00<00:00, 106MB/s]\n",
      "Downloading: 100%|██████████| 1.26k/1.26k [00:00<00:00, 9.52MB/s]\n",
      "Downloading: 100%|██████████| 2.65M/2.65M [00:00<00:00, 51.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "import os\n",
    "# 第一个参数表示下载模型的型号，第二个参数是下载后存放的缓存地址，第三个表示版本号，默认 master\n",
    "model_dir = snapshot_download('Qwen/Qwen2-1.5B-Instruct', cache_dir='qwen2chat_src', revision='master')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0a95d-3a88-4734-8a78-001976f81ffb",
   "metadata": {},
   "source": [
    "# Quantization llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21137ade-132c-48fd-a335-93bdec78e8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T09:38:33.057817Z",
     "iopub.status.busy": "2024-07-20T09:38:33.057373Z",
     "iopub.status.idle": "2024-07-20T09:39:18.631148Z",
     "shell.execute_reply": "2024-07-20T09:39:18.630593Z",
     "shell.execute_reply.started": "2024-07-20T09:38:33.057799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 17:38:45,120 - INFO - Converting the current model to sym_int4 format......\n",
      "2024-07-20 17:38:45,820 - INFO - PyTorch version 2.1.2+cpu available.\n",
      "2024-07-20 17:38:45,821 - INFO - TensorFlow version 2.14.0 available.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-20 17:38:56,910] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from ipex_llm.transformers import AutoModelForCausalLM\n",
    "from transformers import  AutoTokenizer\n",
    "import os\n",
    "if __name__ == '__main__':\n",
    "    model_path = os.path.join(os.getcwd(),\"qwen2chat_src/Qwen/Qwen2-1___5B-Instruct\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, load_in_low_bit='sym_int4', trust_remote_code=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    model.save_low_bit('qwen2chat_int4')\n",
    "    tokenizer.save_pretrained('qwen2chat_int4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef6570-7038-4a43-b019-e71d05b2bc99",
   "metadata": {},
   "source": [
    "# Embedding model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c756f06-01cd-457e-91cb-7d4fe94b2547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T09:39:18.632530Z",
     "iopub.status.busy": "2024-07-20T09:39:18.632013Z",
     "iopub.status.idle": "2024-07-20T09:39:27.087711Z",
     "shell.execute_reply": "2024-07-20T09:39:27.087149Z",
     "shell.execute_reply.started": "2024-07-20T09:39:18.632502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 1.31MB/s]\n",
      "Downloading: 100%|██████████| 776/776 [00:00<00:00, 4.48MB/s]\n",
      "Downloading: 100%|██████████| 124/124 [00:00<00:00, 916kB/s]\n",
      "Downloading: 100%|██████████| 47.0/47.0 [00:00<00:00, 348kB/s]\n",
      "Downloading: 100%|██████████| 91.4M/91.4M [00:00<00:00, 382MB/s]\n",
      "Downloading: 100%|██████████| 349/349 [00:00<00:00, 2.52MB/s]\n",
      "Downloading: 100%|██████████| 91.4M/91.4M [00:00<00:00, 285MB/s]\n",
      "Downloading: 100%|██████████| 27.5k/27.5k [00:00<00:00, 11.3MB/s]\n",
      "Downloading: 100%|██████████| 52.0/52.0 [00:00<00:00, 343kB/s]\n",
      "Downloading: 100%|██████████| 125/125 [00:00<00:00, 926kB/s]\n",
      "Downloading: 100%|██████████| 429k/429k [00:00<00:00, 41.5MB/s]\n",
      "Downloading: 100%|██████████| 367/367 [00:00<00:00, 2.72MB/s]\n",
      "Downloading: 100%|██████████| 107k/107k [00:00<00:00, 8.47MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "import os\n",
    "# 第一个参数表示下载模型的型号，第二个参数是下载后存放的缓存地址，第三个表示版本号，默认 master\n",
    "model_dir = snapshot_download('AI-ModelScope/bge-small-zh-v1.5', cache_dir='qwen2chat_src', revision='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aabb700-ebff-4c43-99c2-67f44aa18ac7",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97aee7-4ce1-445f-b7ad-afa68bba8a1b",
   "metadata": {},
   "source": [
    "## add a ./data folder and upload pdf files to the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3533e575-dc28-46fa-9775-b37e7bef4f2e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-20T09:39:27.088843Z",
     "iopub.status.busy": "2024-07-20T09:39:27.088481Z",
     "iopub.status.idle": "2024-07-20T09:39:27.095577Z",
     "shell.execute_reply": "2024-07-20T09:39:27.095122Z",
     "shell.execute_reply.started": "2024-07-20T09:39:27.088826Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /mnt/workspace/rag.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/workspace/rag.py\n",
    "# 设置OpenMP线程数为8\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "\n",
    "# 从llama_index库导入HuggingFaceEmbedding类，用于将文本转换为向量表示\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# 从llama_index库导入ChromaVectorStore类，用于高效存储和检索向量数据\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "# 从llama_index库导入PyMuPDFReader类，用于读取和解析PDF文件内容\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "# 从llama_index库导入NodeWithScore和TextNode类\n",
    "# NodeWithScore: 表示带有相关性分数的节点，用于排序检索结果\n",
    "# TextNode: 表示文本块，是索引和检索的基本单位。节点存储文本内容及其元数据，便于构建知识图谱和语义搜索\n",
    "from llama_index.core.schema import NodeWithScore, TextNode\n",
    "# 从llama_index库导入RetrieverQueryEngine类，用于协调检索器和响应生成，执行端到端的问答过程\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "# 从llama_index库导入QueryBundle类，用于封装查询相关的信息，如查询文本、过滤器等\n",
    "from llama_index.core import QueryBundle\n",
    "# 从llama_index库导入BaseRetriever类，这是所有检索器的基类，定义了检索接口\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "# 从llama_index库导入SentenceSplitter类，用于将长文本分割成句子或语义完整的文本块，便于索引和检索\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "# 从llama_index库导入VectorStoreQuery类，用于构造向量存储的查询，支持语义相似度搜索\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "# low-level API to compose the query engine, pass streaming=True when constructing the Response Synthesizer\n",
    "from llama_index.core import get_response_synthesizer\n",
    "# 向量数据库\n",
    "import chromadb\n",
    "from ipex_llm.llamaindex.llms import IpexLLM\n",
    "\n",
    "class Config:\n",
    "    \"\"\"配置类,存储所有需要的参数\"\"\"\n",
    "    model_path = \"qwen2chat_int4\"\n",
    "    tokenizer_path = \"qwen2chat_int4\"\n",
    "    question = \"How does Llama 2 perform compared to other open-source models?\"\n",
    "    data_path = \"./data/llamatiny.pdf\"\n",
    "    persist_dir = \"./chroma_db\"\n",
    "    embedding_model_path = \"qwen2chat_src/AI-ModelScope/bge-small-zh-v1___5\"\n",
    "    max_new_tokens = 128\n",
    "\n",
    "def load_vector_database(persist_dir: str) -> ChromaVectorStore:\n",
    "    \"\"\"\n",
    "    加载或创建向量数据库\n",
    "    \n",
    "    Args:\n",
    "        persist_dir (str): 持久化目录路径\n",
    "    \n",
    "    Returns:\n",
    "        ChromaVectorStore: 向量存储对象\n",
    "    \"\"\"\n",
    "    # 检查持久化目录是否存在\n",
    "    if os.path.exists(persist_dir):\n",
    "        print(f\"正在加载现有的向量数据库: {persist_dir}\")\n",
    "        chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "        chroma_collection = chroma_client.get_collection(\"llama2_paper\")\n",
    "    else:\n",
    "        print(f\"创建新的向量数据库: {persist_dir}\")\n",
    "        chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "        chroma_collection = chroma_client.create_collection(\"llama2_paper\")\n",
    "    print(f\"Vector store loaded with {chroma_collection.count()} documents\")\n",
    "    return ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "def load_data(data_path: str) -> List[TextNode]:\n",
    "    \"\"\"\n",
    "    加载并处理PDF数据\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): PDF文件路径\n",
    "    \n",
    "    Returns:\n",
    "        List[TextNode]: 处理后的文本节点列表\n",
    "    \"\"\"\n",
    "    loader = PyMuPDFReader()\n",
    "    documents = loader.load(file_path=data_path)\n",
    "\n",
    "    \n",
    "    #*****************\n",
    "    #Hyperparameter  of the document splitter: chunk_size=384\n",
    "    #************\n",
    "    text_parser = SentenceSplitter(chunk_size=384)\n",
    "    text_chunks = []\n",
    "    doc_idxs = []\n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "        cur_text_chunks = text_parser.split_text(doc.text)\n",
    "        text_chunks.extend(cur_text_chunks)\n",
    "        doc_idxs.extend([doc_idx] * len(cur_text_chunks))\n",
    "\n",
    "    nodes = []\n",
    "    for idx, text_chunk in enumerate(text_chunks):\n",
    "        node = TextNode(text=text_chunk)\n",
    "        src_doc = documents[doc_idxs[idx]]\n",
    "        node.metadata = src_doc.metadata\n",
    "        nodes.append(node)\n",
    "    return nodes\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"向量数据库检索器\"\"\"\n",
    "\n",
    "    \n",
    "    #*****************\n",
    "    #Hyperparameter  of similarity vectors/senetences/window/: similarity_top_k\n",
    "    #************\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: ChromaVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"\n",
    "        检索相关文档\n",
    "        \n",
    "        Args:\n",
    "            query_bundle (QueryBundle): 查询包\n",
    "        \n",
    "        Returns:\n",
    "            List[NodeWithScore]: 检索到的文档节点及其相关性得分\n",
    "        \"\"\"\n",
    "        query_embedding = self._embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = self._vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "        print(f\"Retrieved {len(nodes_with_scores)} nodes with scores\")\n",
    "        return nodes_with_scores\n",
    "\n",
    "def completion_to_prompt(completion: str) -> str:\n",
    "    \"\"\"\n",
    "    将完成转换为提示格式\n",
    "    \n",
    "    Args:\n",
    "        completion (str): 完成的文本\n",
    "    \n",
    "    Returns:\n",
    "        str: 格式化后的提示\n",
    "    \"\"\"\n",
    "    return f\"<|system|>\\n</s>\\n<|user|>\\n{completion}</s>\\n<|assistant|>\\n\"\n",
    "\n",
    "def messages_to_prompt(messages: List[dict]) -> str:\n",
    "    \"\"\"\n",
    "    将消息列表转换为提示格式\n",
    "    \n",
    "    Args:\n",
    "        messages (List[dict]): 消息列表\n",
    "    \n",
    "    Returns:\n",
    "        str: 格式化后的提示\n",
    "    \"\"\"\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"system\":\n",
    "            prompt += f\"<|system|>\\n{message.content}</s>\\n\"\n",
    "        elif message.role == \"user\":\n",
    "            prompt += f\"<|user|>\\n{message.content}</s>\\n\"\n",
    "        elif message.role == \"assistant\":\n",
    "            prompt += f\"<|assistant|>\\n{message.content}</s>\\n\"\n",
    "\n",
    "    if not prompt.startswith(\"<|system|>\\n\"):\n",
    "        prompt = \"<|system|>\\n</s>\\n\" + prompt\n",
    "\n",
    "    prompt = prompt + \"<|assistant|>\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def setup_llm(config: Config) -> IpexLLM:\n",
    "    \"\"\"\n",
    "    设置语言模型\n",
    "    \n",
    "    Args:\n",
    "        config (Config): 配置对象\n",
    "    \n",
    "    Returns:\n",
    "        IpexLLM: 配置好的语言模型\n",
    "    \"\"\"\n",
    "    #*****************\n",
    "    #Hyperparameter  do_sample\n",
    "    #************\n",
    "    return IpexLLM.from_model_id_low_bit(\n",
    "        model_name=config.model_path,\n",
    "        tokenizer_name=config.tokenizer_path,\n",
    "        context_window=384,\n",
    "        max_new_tokens=config.max_new_tokens,\n",
    "        generate_kwargs={\"temperature\": 0.7, \"do_sample\": True},\n",
    "        model_kwargs={},\n",
    "        messages_to_prompt=messages_to_prompt,\n",
    "        completion_to_prompt=completion_to_prompt,\n",
    "        device_map=\"cpu\",\n",
    "    )\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    config = Config()\n",
    "    config.question = message\n",
    "    # 设置嵌入模型\n",
    "    embed_model = HuggingFaceEmbedding(model_name=config.embedding_model_path)\n",
    "    \n",
    "    # 设置语言模型\n",
    "    llm = setup_llm(config)\n",
    "    \n",
    "    # 加载向量数据库\n",
    "    vector_store = load_vector_database(persist_dir=config.persist_dir)\n",
    "    \n",
    "    # 加载和处理数据\n",
    "    nodes = load_data(data_path=config.data_path)\n",
    "    for node in nodes:\n",
    "        node_embedding = embed_model.get_text_embedding(\n",
    "            node.get_content(metadata_mode=\"all\")\n",
    "        )\n",
    "        node.embedding = node_embedding\n",
    "    \n",
    "    # 将 node 添加到向量存储\n",
    "    vector_store.add(nodes)\n",
    "    \n",
    "    # 设置查询\n",
    "    query_str = config.question\n",
    "    query_embedding = embed_model.get_query_embedding(query_str)\n",
    "    \n",
    "    # 执行向量存储检索\n",
    "    print(\"开始执行向量存储检索\")\n",
    "    query_mode = \"default\"\n",
    "    vector_store_query = VectorStoreQuery(\n",
    "        query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    "    )\n",
    "    query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "    # 处理查询结果\n",
    "    print(\"开始处理检索结果\")\n",
    "    nodes_with_scores = []\n",
    "    for index, node in enumerate(query_result.nodes):\n",
    "        score: Optional[float] = None\n",
    "        if query_result.similarities is not None:\n",
    "            score = query_result.similarities[index]\n",
    "        nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "    \n",
    "    # 设置检索器\n",
    "    retriever = VectorDBRetriever(\n",
    "        vector_store, embed_model, query_mode=\"default\", similarity_top_k=1\n",
    "    )\n",
    "    \n",
    "    print(f\"Query engine created with retriever: {type(retriever).__name__}\")\n",
    "    print(f\"Query string length: {len(query_str)}\")\n",
    "    print(f\"Query string: {query_str}\")\n",
    "    \n",
    "    # 创建查询引擎\n",
    "    \n",
    "    print(\"准备与llm对话\")\n",
    "    synth = get_response_synthesizer(streaming=True,llm=llm)\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm, response_synthesizer=synth)\n",
    "\n",
    "    # 执行查询\n",
    "    print(\"开始RAG最后生成\")\n",
    "    response = query_engine.query(query_str)\n",
    "    response.print_response_stream()\n",
    "    \n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "269ccd8a-9086-4f1e-8ba1-3e0a75bb4364",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-20T09:45:19.104510Z",
     "iopub.status.busy": "2024-07-20T09:45:19.104212Z",
     "iopub.status.idle": "2024-07-20T09:45:19.113033Z",
     "shell.execute_reply": "2024-07-20T09:45:19.112403Z",
     "shell.execute_reply.started": "2024-07-20T09:45:19.104488Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/workspace/rag_gradio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/workspace/rag_gradio.py\n",
    "# 设置OpenMP线程数为8\n",
    "import os\n",
    "import time\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "import torch\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, TextIteratorStreamer\n",
    "from ipex_llm.transformers import AutoModelForCausalLM\n",
    "from ipex_llm.llamaindex.llms import IpexLLM\n",
    "import torch\n",
    "from threading import Thread, Event\n",
    "\n",
    "\n",
    "\n",
    "import rag\n",
    "\n",
    "\n",
    "# 从llama_index库导入HuggingFaceEmbedding类，用于将文本转换为向量表示\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# 从llama_index库导入VectorStoreQuery类，用于构造向量存储的查询，支持语义相似度搜索\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "# 从llama_index库导入RetrieverQueryEngine类，用于协调检索器和响应生成，执行端到端的问答过程\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "# NodeWithScore: 表示带有相关性分数的节点，用于排序检索结果\n",
    "# TextNode: 表示文本块，是索引和检索的基本单位。节点存储文本内容及其元数据，便于构建知识图谱和语义搜索\n",
    "from llama_index.core.schema import NodeWithScore, TextNode\n",
    "\n",
    "\n",
    "\n",
    "config = rag.Config()\n",
    "# config.question = message\n",
    "# 设置嵌入模型\n",
    "embed_model = HuggingFaceEmbedding(model_name=config.embedding_model_path)\n",
    "\n",
    "# 设置语言模型\n",
    "llm = rag.setup_llm(config)\n",
    "\n",
    "# 加载向量数据库\n",
    "vector_store = rag.load_vector_database(persist_dir=config.persist_dir)\n",
    "\n",
    "# 加载和处理数据\n",
    "nodes = rag.load_data(data_path=config.data_path)\n",
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding\n",
    "\n",
    "# 将 node 添加到向量存储\n",
    "vector_store.add(nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################rag start#########################\n",
    "\n",
    "# 加载模型和tokenizer\n",
    "load_path = \"qwen2chat_int4\"  # 模型路径\n",
    "model = AutoModelForCausalLM.load_low_bit(load_path, trust_remote_code=True)  # 加载低位模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_path, trust_remote_code=True)  # 加载对应的tokenizer\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 检查是否有GPU可用\n",
    "model = model.to(device)  # 将模型移动到选定的设备上\n",
    "\n",
    "# 创建 TextIteratorStreamer，用于流式生成文本\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "# 创建一个停止事件，用于控制生成过程的中断\n",
    "stop_event = Event()\n",
    "\n",
    "# 定义用户输入处理函数\n",
    "def user(user_message, history):\n",
    "    return \"\", history + [[user_message, None]]  # 返回空字符串和更新后的历史记录\n",
    "\n",
    "# 定义机器人回复生成函数\n",
    "def bot(history):\n",
    "    stop_event.clear()  # 重置停止事件\n",
    "    prompt = history[-1][0]  # 获取最新的用户输入\n",
    "    \n",
    "    \n",
    "    ######################rag query#################################\n",
    "    # 设置查询\n",
    "    config.question = prompt\n",
    "    query_str = prompt\n",
    "    query_embedding = embed_model.get_query_embedding(prompt)\n",
    "\n",
    "    # 执行向量存储检索\n",
    "    print(\"开始执行向量存储检索\")\n",
    "    query_mode = \"default\"\n",
    "    vector_store_query = VectorStoreQuery(\n",
    "        query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    "    )\n",
    "    query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "    # 处理查询结果\n",
    "    print(\"开始处理检索结果\")\n",
    "    nodes_with_scores = []\n",
    "    for index, node in enumerate(query_result.nodes):\n",
    "        score: Optional[float] = None\n",
    "        if query_result.similarities is not None:\n",
    "            score = query_result.similarities[index]\n",
    "        nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "    # 设置检索器\n",
    "    retriever = rag.VectorDBRetriever(\n",
    "        vector_store, embed_model, query_mode=\"default\", similarity_top_k=1\n",
    "    )\n",
    "\n",
    "    print(f\"Query engine created with retriever: {type(retriever).__name__}\")\n",
    "    print(f\"Query string length: {len(query_str)}\")\n",
    "    print(f\"Query string: {query_str}\")\n",
    "\n",
    "    # 创建查询引擎\n",
    "\n",
    "    print(\"准备与llm对话\")\n",
    "    # synth = get_response_synthesizer(streaming=True,llm=llm)\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\n",
    "\n",
    "    # 执行查询\n",
    "    print(\"开始RAG最后生成\")\n",
    "    response_rag = query_engine.query(query_str)\n",
    "    print(\"response\")\n",
    "    print(str(response_rag))\n",
    "    ######################rag query end#################################\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    chat with history\n",
    "    (small llms have some problem with chatting, so try to muti tests)\n",
    "    '''\n",
    "    messages = []\n",
    "    for user_msg, response in history:\n",
    "        if user_msg and not response:  # 如果当前正在处理的用户消息没有响应\n",
    "            break  # 结束循环，只考虑之前的对话\n",
    "        messages.extend([\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ])\n",
    "        \n",
    "    messages.extend([\n",
    "            {\"role\": \"user\", \"content\": f\"{response_rag}\\n{prompt}\"}\n",
    "        ])\n",
    "    print(messages) \n",
    "    #     messages = [{\"role\": \"user\", \"content\": prompt}]  # 构建消息格式\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)  # 应用聊天模板\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)  # 对输入进行编码并移到指定设备\n",
    "    \n",
    "    print(f\"\\n用户输入: {prompt}\")\n",
    "    print(\"模型输出: \", end=\"\", flush=True)\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "\n",
    "    # 设置生成参数\n",
    "    generation_kwargs = dict(\n",
    "        model_inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=512,  # 最大生成512个新token\n",
    "        do_sample=True,  # 使用采样\n",
    "        top_p=0.7,  # 使用top-p采样\n",
    "        temperature=0.95,  # 控制生成的随机性\n",
    "    )\n",
    "\n",
    "    # 在新线程中运行模型生成\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "\n",
    "    generated_text = \"\"\n",
    "    for new_text in streamer:  # 迭代生成的文本流\n",
    "        if stop_event.is_set():  # 检查是否需要停止生成\n",
    "            print(\"\\n生成被用户停止\")\n",
    "            break\n",
    "        generated_text += new_text\n",
    "        print(new_text, end=\"\", flush=True)\n",
    "        history[-1][1] = generated_text  # 更新历史记录中的回复\n",
    "        yield history  # 逐步返回更新的历史记录\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n\\n生成完成，用时: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 定义停止生成函数\n",
    "def stop_generation():\n",
    "    stop_event.set()  # 设置停止事件\n",
    "\n",
    "# 使用Gradio创建Web界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Qwen 聊天机器人\")\n",
    "    chatbot = gr.Chatbot()  # 聊天界面组件\n",
    "    msg = gr.Textbox()  # 用户输入文本框\n",
    "    clear = gr.Button(\"清除\")  # 清除按钮\n",
    "    stop = gr.Button(\"停止生成\")  # 停止生成按钮\n",
    "\n",
    "    # 设置用户输入提交后的处理流程\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)  # 清除按钮功能\n",
    "    stop.click(stop_generation, queue=False)  # 停止生成按钮功能\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"启动 Gradio 界面...\")\n",
    "    demo.queue()  # 启用队列处理请求\n",
    "    demo.launch(root_path='/dsw-579143/proxy/7860/')  # 兼容魔搭情况下的路由\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762e994-c7f2-44ce-8eb3-52935264552f",
   "metadata": {},
   "source": [
    "chage the demo.launch(root_path='/dsw-xxxxxxxx/proxy/7860/') before run .py\n",
    "```python\n",
    "python3 rag_gradio.py\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
